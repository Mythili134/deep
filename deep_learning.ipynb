{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbJQX6igRLHvrDSIjj6n8B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mythili134/deep/blob/main/deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47ptmC1KVFiZ",
        "outputId": "393b4743-1128-4b3e-c5b2-ed1a180e81c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 10791.1123 - val_loss: 5333.9536\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 1640.2516 - val_loss: 62.8732\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 21.9904 - val_loss: 14.3157\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 10.4112 - val_loss: 8.5482\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 6.8383 - val_loss: 6.1229\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 5.2426 - val_loss: 4.6868\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 4.1496 - val_loss: 3.7073\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 3.2878 - val_loss: 2.9329\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 2.6087 - val_loss: 2.3237\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 2.0724 - val_loss: 1.8218\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 1.5880 - val_loss: 1.4135\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 1.1754 - val_loss: 0.9795\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.8162 - val_loss: 0.6689\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5559 - val_loss: 0.4555\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 0.3433\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.2933 - val_loss: 0.2572\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.2256 - val_loss: 0.2045\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1796 - val_loss: 0.1657\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1433 - val_loss: 0.1338\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1164 - val_loss: 0.1081\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.0950 - val_loss: 0.0874\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.0779 - val_loss: 0.0730\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.0653 - val_loss: 0.0589\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.0539 - val_loss: 0.0487\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0453 - val_loss: 0.0410\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0353\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.0308\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0314 - val_loss: 0.0274\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0236\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0268 - val_loss: 0.0231\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0200\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0188\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0161\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0199 - val_loss: 0.0149\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0134\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.0130\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0155 - val_loss: 0.0117\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0144 - val_loss: 0.0113\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0154\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0129 - val_loss: 0.0111\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0103\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0100\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0101\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0105\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0124 - val_loss: 0.0092\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0090\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0092\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0069\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0120\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0059\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Test Loss: 0.007711379323154688\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "predicted Sum: 68.01091003417969\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_data(num_samples):\n",
        "  x1 = np.random.randint(0, 100, size=num_samples)\n",
        "  x2 = np.random.randint(0, 100, size=num_samples)\n",
        "  y = x1 + x2\n",
        "  return np.vstack((x1,x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'predicted Sum: {predicted_sum[0][0]}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_data(num_samples):\n",
        "  x1 = np.random.randint(0, 100, size=num_samples)\n",
        "  x2 = np.random.randint(0, 100, size=num_samples)\n",
        "  y = x1 + x2\n",
        "  return np.vstack((x1,x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=40, validation_split=0.2)\n",
        "\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT2rb-iOh9-n",
        "outputId": "98ebc393-4804-41a3-ae2c-f9e957aeaf73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 2548.2979 - val_loss: 159.2366\n",
            "Epoch 2/30\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 102.3960 - val_loss: 60.3750\n",
            "Epoch 3/30\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 47.5074 - val_loss: 31.6049\n",
            "Epoch 4/30\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 24.9962 - val_loss: 16.5599\n",
            "Epoch 5/30\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 13.0238 - val_loss: 8.4560\n",
            "Epoch 6/30\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 6.6252 - val_loss: 4.2243\n",
            "Epoch 7/30\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 3.3439 - val_loss: 2.1398\n",
            "Epoch 8/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.7658 - val_loss: 1.1798\n",
            "Epoch 9/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0583 - val_loss: 0.7772\n",
            "Epoch 10/30\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.7634 - val_loss: 0.6198\n",
            "Epoch 11/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6405 - val_loss: 0.5451\n",
            "Epoch 12/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.5779 - val_loss: 0.5089\n",
            "Epoch 13/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.5373 - val_loss: 0.4729\n",
            "Epoch 14/30\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.5014 - val_loss: 0.4403\n",
            "Epoch 15/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.4635 - val_loss: 0.4099\n",
            "Epoch 16/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4300 - val_loss: 0.3799\n",
            "Epoch 17/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.3916 - val_loss: 0.3456\n",
            "Epoch 18/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3567 - val_loss: 0.3174\n",
            "Epoch 19/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.3215 - val_loss: 0.2842\n",
            "Epoch 20/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2901 - val_loss: 0.2540\n",
            "Epoch 21/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2571 - val_loss: 0.2271\n",
            "Epoch 22/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2299 - val_loss: 0.2003\n",
            "Epoch 23/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2013 - val_loss: 0.1758\n",
            "Epoch 24/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1749 - val_loss: 0.1534\n",
            "Epoch 25/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1406\n",
            "Epoch 26/30\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1306 - val_loss: 0.1131\n",
            "Epoch 27/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1084 - val_loss: 0.0953\n",
            "Epoch 28/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0922 - val_loss: 0.0833\n",
            "Epoch 29/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0649\n",
            "Epoch 30/30\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0526\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0499\n",
            "Test Loss: 0.04994649812579155\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "predicted Sum: 67.9135513305664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_data(num_samples):\n",
        "  x1 = np.random.randint(0, 100, size=num_samples)\n",
        "  x2 = np.random.randint(0, 100, size=num_samples)\n",
        "  y = x1 + x2\n",
        "  return np.vstack((x1,x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train, y_train, epochs=54, batch_size=34, validation_split=0.2)\n",
        "\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK7b-YoMiWkZ",
        "outputId": "44a7ca78-6ac8-438b-c4ff-f7f204e44f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 9477.4004 - val_loss: 5460.2036\n",
            "Epoch 2/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 2189.8782 - val_loss: 517.2156\n",
            "Epoch 3/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 336.5750 - val_loss: 199.8627\n",
            "Epoch 4/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 102.8832 - val_loss: 43.0884\n",
            "Epoch 5/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 20.6596 - val_loss: 9.2416\n",
            "Epoch 6/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 5.4891 - val_loss: 3.6685\n",
            "Epoch 7/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 2.5607 - val_loss: 2.0508\n",
            "Epoch 8/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 1.4854 - val_loss: 1.2714\n",
            "Epoch 9/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 0.9474 - val_loss: 0.8604\n",
            "Epoch 10/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 0.6555 - val_loss: 0.6268\n",
            "Epoch 11/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 0.4919 - val_loss: 0.4860\n",
            "Epoch 12/54\n",
            "189/189 [==============================] - 0s 3ms/step - loss: 0.3928 - val_loss: 0.4001\n",
            "Epoch 13/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 0.3304 - val_loss: 0.3387\n",
            "Epoch 14/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 0.2867 - val_loss: 0.2963\n",
            "Epoch 15/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 0.2538 - val_loss: 0.2644\n",
            "Epoch 16/54\n",
            "189/189 [==============================] - 1s 4ms/step - loss: 0.2272 - val_loss: 0.2345\n",
            "Epoch 17/54\n",
            "189/189 [==============================] - 1s 4ms/step - loss: 0.2039 - val_loss: 0.2086\n",
            "Epoch 18/54\n",
            "189/189 [==============================] - 1s 4ms/step - loss: 0.1832 - val_loss: 0.1873\n",
            "Epoch 19/54\n",
            "189/189 [==============================] - 1s 5ms/step - loss: 0.1642 - val_loss: 0.1658\n",
            "Epoch 20/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 0.1465 - val_loss: 0.1470\n",
            "Epoch 21/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 0.1287 - val_loss: 0.1299\n",
            "Epoch 22/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 0.1123 - val_loss: 0.1114\n",
            "Epoch 23/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0954\n",
            "Epoch 24/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 0.0823 - val_loss: 0.0801\n",
            "Epoch 25/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0664\n",
            "Epoch 26/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 0.0563 - val_loss: 0.0532\n",
            "Epoch 27/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0427\n",
            "Epoch 28/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 0.0357 - val_loss: 0.0336\n",
            "Epoch 29/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0252\n",
            "Epoch 30/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 0.0205 - val_loss: 0.0185\n",
            "Epoch 31/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0135\n",
            "Epoch 32/54\n",
            "189/189 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0095\n",
            "Epoch 33/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0064\n",
            "Epoch 34/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 0.0048 - val_loss: 0.0043\n",
            "Epoch 35/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0029\n",
            "Epoch 36/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 37/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 38/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 8.5269e-04 - val_loss: 9.9179e-04\n",
            "Epoch 39/54\n",
            "189/189 [==============================] - 0s 3ms/step - loss: 6.0705e-04 - val_loss: 7.9704e-04\n",
            "Epoch 40/54\n",
            "189/189 [==============================] - 1s 4ms/step - loss: 4.7598e-04 - val_loss: 6.7050e-04\n",
            "Epoch 41/54\n",
            "189/189 [==============================] - 1s 6ms/step - loss: 4.0214e-04 - val_loss: 5.9254e-04\n",
            "Epoch 42/54\n",
            "189/189 [==============================] - 1s 6ms/step - loss: 3.5915e-04 - val_loss: 5.4017e-04\n",
            "Epoch 43/54\n",
            "189/189 [==============================] - 1s 6ms/step - loss: 3.2883e-04 - val_loss: 4.9947e-04\n",
            "Epoch 44/54\n",
            "189/189 [==============================] - 1s 6ms/step - loss: 3.0803e-04 - val_loss: 4.6695e-04\n",
            "Epoch 45/54\n",
            "189/189 [==============================] - 1s 5ms/step - loss: 2.9080e-04 - val_loss: 4.3661e-04\n",
            "Epoch 46/54\n",
            "189/189 [==============================] - 1s 4ms/step - loss: 2.7508e-04 - val_loss: 4.0868e-04\n",
            "Epoch 47/54\n",
            "189/189 [==============================] - 0s 3ms/step - loss: 2.6103e-04 - val_loss: 3.8725e-04\n",
            "Epoch 48/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 2.4816e-04 - val_loss: 3.5915e-04\n",
            "Epoch 49/54\n",
            "189/189 [==============================] - 1s 3ms/step - loss: 2.3605e-04 - val_loss: 3.3585e-04\n",
            "Epoch 50/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 2.2454e-04 - val_loss: 3.1372e-04\n",
            "Epoch 51/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 2.1445e-04 - val_loss: 2.9277e-04\n",
            "Epoch 52/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 2.0432e-04 - val_loss: 2.7482e-04\n",
            "Epoch 53/54\n",
            "189/189 [==============================] - 0s 2ms/step - loss: 1.9268e-04 - val_loss: 2.4946e-04\n",
            "Epoch 54/54\n",
            "189/189 [==============================] - 0s 3ms/step - loss: 1.8313e-04 - val_loss: 2.3334e-04\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 5.5933e-04\n",
            "Test Loss: 0.0005593323148787022\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "predicted Sum: 67.99890899658203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_data(num_samples):\n",
        "  x1 = np.random.randint(0, 100, size=num_samples)\n",
        "  x2 = np.random.randint(0, 100, size=num_samples)\n",
        "  y = x1 + x2\n",
        "  return np.vstack((x1,x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfBeCVz5irgR",
        "outputId": "7b25da48-5bd4-444c-88f4-7ce6eb1668ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "200/200 [==============================] - 2s 4ms/step - loss: 13091.4941 - val_loss: 7896.2451\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3294.6821 - val_loss: 288.3784\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 51.4660 - val_loss: 10.8216\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 8.7506 - val_loss: 6.3181\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 4.9382 - val_loss: 3.4782\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 2.6749 - val_loss: 1.9083\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.5131 - val_loss: 1.1550\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.9854 - val_loss: 0.8343\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.7617 - val_loss: 0.6903\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6549 - val_loss: 0.6102\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5881 - val_loss: 0.5525\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 0.5053\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.4820 - val_loss: 0.4548\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4343 - val_loss: 0.4080\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3896 - val_loss: 0.3660\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.3277\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3121 - val_loss: 0.2946\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2791 - val_loss: 0.2637\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2497 - val_loss: 0.2381\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2244 - val_loss: 0.2139\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.2178\n",
            "Test Loss: 0.21779365837574005\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "predicted Sum: 68.55738830566406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_data(num_samples):\n",
        "  x1 = np.random.randint(0, 100, size=num_samples)\n",
        "  x2 = np.random.randint(0, 100, size=num_samples)\n",
        "  y = x1 + x2\n",
        "  return np.vstack((x1,x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train, y_train, epochs=40, batch_size=18, validation_split=0.2)\n",
        "\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp5hkqAMjQnP",
        "outputId": "277128db-4b21-406f-c815-5cc0db37184d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "356/356 [==============================] - 2s 3ms/step - loss: 274.7186 - val_loss: 5.8874\n",
            "Epoch 2/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 4.0479 - val_loss: 2.8794\n",
            "Epoch 3/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 2.1628 - val_loss: 1.5269\n",
            "Epoch 4/40\n",
            "356/356 [==============================] - 1s 3ms/step - loss: 1.1118 - val_loss: 0.7297\n",
            "Epoch 5/40\n",
            "356/356 [==============================] - 2s 4ms/step - loss: 0.5380 - val_loss: 0.3346\n",
            "Epoch 6/40\n",
            "356/356 [==============================] - 1s 4ms/step - loss: 0.2579 - val_loss: 0.1763\n",
            "Epoch 7/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 0.1409 - val_loss: 0.1014\n",
            "Epoch 8/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 0.0866 - val_loss: 0.0652\n",
            "Epoch 9/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 0.0570 - val_loss: 0.0418\n",
            "Epoch 10/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 0.0364 - val_loss: 0.0273\n",
            "Epoch 11/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 0.0222 - val_loss: 0.0162\n",
            "Epoch 12/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 0.0134 - val_loss: 0.0097\n",
            "Epoch 13/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0059\n",
            "Epoch 14/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 0.0047 - val_loss: 0.0036\n",
            "Epoch 15/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 0.0029 - val_loss: 0.0018\n",
            "Epoch 16/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 0.0017 - val_loss: 0.0010\n",
            "Epoch 17/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 0.0010 - val_loss: 6.7527e-04\n",
            "Epoch 18/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 6.8009e-04 - val_loss: 4.5397e-04\n",
            "Epoch 19/40\n",
            "356/356 [==============================] - 1s 3ms/step - loss: 4.5371e-04 - val_loss: 3.2579e-04\n",
            "Epoch 20/40\n",
            "356/356 [==============================] - 1s 4ms/step - loss: 2.8444e-04 - val_loss: 2.0280e-04\n",
            "Epoch 21/40\n",
            "356/356 [==============================] - 2s 4ms/step - loss: 2.0639e-04 - val_loss: 1.3597e-04\n",
            "Epoch 22/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 1.5407e-04 - val_loss: 7.2809e-05\n",
            "Epoch 23/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 1.0905e-04 - val_loss: 9.1079e-05\n",
            "Epoch 24/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 6.9500e-05 - val_loss: 4.0983e-05\n",
            "Epoch 25/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 5.3010e-05 - val_loss: 2.8753e-05\n",
            "Epoch 26/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 3.9488e-05 - val_loss: 2.0625e-05\n",
            "Epoch 27/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 3.7334e-05 - val_loss: 1.4180e-05\n",
            "Epoch 28/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 2.7685e-05 - val_loss: 1.0246e-04\n",
            "Epoch 29/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 3.3147e-05 - val_loss: 1.6072e-05\n",
            "Epoch 30/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 3.6046e-05 - val_loss: 2.6328e-05\n",
            "Epoch 31/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 9.3415e-05 - val_loss: 2.5948e-05\n",
            "Epoch 32/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 4.9798e-04 - val_loss: 4.0589e-05\n",
            "Epoch 33/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 9.7161e-04\n",
            "Epoch 34/40\n",
            "356/356 [==============================] - 1s 4ms/step - loss: 3.6332e-04 - val_loss: 3.0733e-06\n",
            "Epoch 35/40\n",
            "356/356 [==============================] - 1s 4ms/step - loss: 3.0717e-06 - val_loss: 2.0906e-06\n",
            "Epoch 36/40\n",
            "356/356 [==============================] - 1s 3ms/step - loss: 2.3295e-06 - val_loss: 1.1112e-06\n",
            "Epoch 37/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 2.7910e-06 - val_loss: 4.7580e-06\n",
            "Epoch 38/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 3.3744e-04 - val_loss: 0.0044\n",
            "Epoch 39/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 8.9943e-04 - val_loss: 3.2957e-07\n",
            "Epoch 40/40\n",
            "356/356 [==============================] - 1s 2ms/step - loss: 0.0027 - val_loss: 0.0072\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Test Loss: 0.0072573525831103325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d4e9fad3ac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n",
            "predicted Sum: 68.06671142578125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_data(num_samples):\n",
        "  x1 = np.random.randint(0, 100, size=num_samples)\n",
        "  x2 = np.random.randint(0, 100, size=num_samples)\n",
        "  y = x1 + x2\n",
        "  return np.vstack((x1,x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train, y_train, epochs=19, batch_size=33, validation_split=0.2)\n",
        "\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09tyh3xWjv3x",
        "outputId": "2d206403-71aa-4f0b-b280-1892cba9104f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/19\n",
            "194/194 [==============================] - 2s 6ms/step - loss: 6307.0430 - val_loss: 2120.9041\n",
            "Epoch 2/19\n",
            "194/194 [==============================] - 1s 5ms/step - loss: 565.7997 - val_loss: 126.2665\n",
            "Epoch 3/19\n",
            "194/194 [==============================] - 1s 5ms/step - loss: 71.4882 - val_loss: 29.5570\n",
            "Epoch 4/19\n",
            "194/194 [==============================] - 1s 4ms/step - loss: 14.0484 - val_loss: 4.5560\n",
            "Epoch 5/19\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 2.2249 - val_loss: 1.0126\n",
            "Epoch 6/19\n",
            "194/194 [==============================] - 1s 5ms/step - loss: 0.7551 - val_loss: 0.5546\n",
            "Epoch 7/19\n",
            "194/194 [==============================] - 1s 5ms/step - loss: 0.4905 - val_loss: 0.3965\n",
            "Epoch 8/19\n",
            "194/194 [==============================] - 1s 5ms/step - loss: 0.3645 - val_loss: 0.3031\n",
            "Epoch 9/19\n",
            "194/194 [==============================] - 1s 5ms/step - loss: 0.2851 - val_loss: 0.2437\n",
            "Epoch 10/19\n",
            "194/194 [==============================] - 0s 2ms/step - loss: 0.2338 - val_loss: 0.2043\n",
            "Epoch 11/19\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.1995 - val_loss: 0.1780\n",
            "Epoch 12/19\n",
            "194/194 [==============================] - 0s 2ms/step - loss: 0.1761 - val_loss: 0.1592\n",
            "Epoch 13/19\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.1596 - val_loss: 0.1466\n",
            "Epoch 14/19\n",
            "194/194 [==============================] - 0s 2ms/step - loss: 0.1473 - val_loss: 0.1358\n",
            "Epoch 15/19\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.1376 - val_loss: 0.1279\n",
            "Epoch 16/19\n",
            "194/194 [==============================] - 0s 2ms/step - loss: 0.1295 - val_loss: 0.1211\n",
            "Epoch 17/19\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.1225 - val_loss: 0.1154\n",
            "Epoch 18/19\n",
            "194/194 [==============================] - 0s 2ms/step - loss: 0.1156 - val_loss: 0.1084\n",
            "Epoch 19/19\n",
            "194/194 [==============================] - 1s 3ms/step - loss: 0.1092 - val_loss: 0.1026\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.1059\n",
            "Test Loss: 0.10594183951616287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d4e9e0e4e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 83ms/step\n",
            "predicted Sum: 68.25179290771484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_data(num_samples):\n",
        "  x1 = np.random.randint(0, 100, size=num_samples)\n",
        "  x2 = np.random.randint(0, 100, size=num_samples)\n",
        "  y = x1 + x2\n",
        "  return np.vstack((x1,x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train, y_train, epochs=40, batch_size=22, validation_split=0.2)\n",
        "\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc7KFLcOkMiz",
        "outputId": "ccdb7e01-c03a-48e7-b7b0-9aea44b00c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "291/291 [==============================] - 2s 3ms/step - loss: 3279.6851 - val_loss: 5.3416\n",
            "Epoch 2/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 3.5387 - val_loss: 2.2375\n",
            "Epoch 3/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 1.7032 - val_loss: 1.2455\n",
            "Epoch 4/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 1.1508 - val_loss: 0.9741\n",
            "Epoch 5/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.9624 - val_loss: 0.8455\n",
            "Epoch 6/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.8376 - val_loss: 0.7441\n",
            "Epoch 7/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.7341 - val_loss: 0.6376\n",
            "Epoch 8/40\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.6424 - val_loss: 0.5524\n",
            "Epoch 9/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.5528 - val_loss: 0.4947\n",
            "Epoch 10/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.4169 - val_loss: 0.2250\n",
            "Epoch 11/40\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0900 - val_loss: 0.0306\n",
            "Epoch 12/40\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0268 - val_loss: 0.0191\n",
            "Epoch 13/40\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0181 - val_loss: 0.0156\n",
            "Epoch 14/40\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0140\n",
            "Epoch 15/40\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0130 - val_loss: 0.0120\n",
            "Epoch 16/40\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0121 - val_loss: 0.0112\n",
            "Epoch 17/40\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0114 - val_loss: 0.0109\n",
            "Epoch 18/40\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0103 - val_loss: 0.0098\n",
            "Epoch 19/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0096 - val_loss: 0.0085\n",
            "Epoch 20/40\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0080\n",
            "Epoch 21/40\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0074\n",
            "Epoch 22/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0064\n",
            "Epoch 23/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0053\n",
            "Epoch 24/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0055 - val_loss: 0.0043\n",
            "Epoch 25/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0045 - val_loss: 0.0034\n",
            "Epoch 26/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0042 - val_loss: 0.0035\n",
            "Epoch 27/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0029 - val_loss: 0.0018\n",
            "Epoch 28/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0021 - val_loss: 0.0015\n",
            "Epoch 29/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0014 - val_loss: 9.4055e-04\n",
            "Epoch 30/40\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 8.3638e-04 - val_loss: 3.4321e-04\n",
            "Epoch 31/40\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 4.8724e-04 - val_loss: 2.4510e-04\n",
            "Epoch 32/40\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 1.8614e-04 - val_loss: 1.1789e-04\n",
            "Epoch 33/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 6.3379e-05 - val_loss: 1.4681e-05\n",
            "Epoch 34/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 1.8355e-05 - val_loss: 6.2503e-06\n",
            "Epoch 35/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 1.0396e-05 - val_loss: 6.9908e-07\n",
            "Epoch 36/40\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 6.6106e-06 - val_loss: 8.3066e-07\n",
            "Epoch 37/40\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 5.0022e-05 - val_loss: 6.8331e-07\n",
            "Epoch 38/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0011 - val_loss: 7.2823e-07\n",
            "Epoch 39/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 5.4802e-06 - val_loss: 1.0479e-07\n",
            "Epoch 40/40\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 1.1495e-04 - val_loss: 5.2533e-05\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 5.1791e-05\n",
            "Test Loss: 5.1791030273307115e-05\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "predicted Sum: 67.99415588378906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_data(num_samples):\n",
        "  x1 = np.random.randint(0, 100, size=num_samples)\n",
        "  x2 = np.random.randint(0, 100, size=num_samples)\n",
        "  y = x1 + x2\n",
        "  return np.vstack((x1,x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=29, validation_split=0.2)\n",
        "\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C60LokpXkbsj",
        "outputId": "f19222b8-d0e7-4e92-a259-5035d5fdc02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "221/221 [==============================] - 2s 4ms/step - loss: 5062.6904 - val_loss: 140.9954\n",
            "Epoch 2/10\n",
            "221/221 [==============================] - 1s 5ms/step - loss: 60.5631 - val_loss: 28.0358\n",
            "Epoch 3/10\n",
            "221/221 [==============================] - 1s 5ms/step - loss: 21.4323 - val_loss: 14.5102\n",
            "Epoch 4/10\n",
            "221/221 [==============================] - 1s 5ms/step - loss: 11.4541 - val_loss: 7.2286\n",
            "Epoch 5/10\n",
            "221/221 [==============================] - 1s 4ms/step - loss: 4.8544 - val_loss: 2.4065\n",
            "Epoch 6/10\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 1.8484 - val_loss: 1.2022\n",
            "Epoch 7/10\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 1.1618 - val_loss: 0.8545\n",
            "Epoch 8/10\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.8614 - val_loss: 0.6412\n",
            "Epoch 9/10\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.6527 - val_loss: 0.4937\n",
            "Epoch 10/10\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5021 - val_loss: 0.3911\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4819\n",
            "Test Loss: 0.4819144308567047\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "predicted Sum: 68.16287994384766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def generate_data(num_samples):\n",
        "  x1 = np.random.randint(0, 100, size=num_samples)\n",
        "  x2 = np.random.randint(0, 100, size=num_samples)\n",
        "  y = x1 + x2\n",
        "  return np.vstack((x1,x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train, y_train, epochs=34, batch_size=27, validation_split=0.2)\n",
        "\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjlWB4Q6klEA",
        "outputId": "23ee15b6-2086-4c3a-f57c-c1e311b8589e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/34\n",
            "238/238 [==============================] - 2s 4ms/step - loss: 2515.7788 - val_loss: 99.7920\n",
            "Epoch 2/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 30.0174 - val_loss: 3.7779\n",
            "Epoch 3/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 1.4400 - val_loss: 0.6773\n",
            "Epoch 4/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.4416 - val_loss: 0.3340\n",
            "Epoch 5/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.2813 - val_loss: 0.2535\n",
            "Epoch 6/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.2324 - val_loss: 0.2212\n",
            "Epoch 7/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.2015 - val_loss: 0.1936\n",
            "Epoch 8/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.1750 - val_loss: 0.1603\n",
            "Epoch 9/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.1507 - val_loss: 0.1417\n",
            "Epoch 10/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.1276 - val_loss: 0.1140\n",
            "Epoch 11/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.1077 - val_loss: 0.0991\n",
            "Epoch 12/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.0907 - val_loss: 0.0794\n",
            "Epoch 13/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.0755 - val_loss: 0.0735\n",
            "Epoch 14/34\n",
            "238/238 [==============================] - 1s 4ms/step - loss: 0.0623 - val_loss: 0.0551\n",
            "Epoch 15/34\n",
            "238/238 [==============================] - 1s 5ms/step - loss: 0.0520 - val_loss: 0.0440\n",
            "Epoch 16/34\n",
            "238/238 [==============================] - 1s 5ms/step - loss: 0.0420 - val_loss: 0.0361\n",
            "Epoch 17/34\n",
            "238/238 [==============================] - 1s 4ms/step - loss: 0.0344 - val_loss: 0.0342\n",
            "Epoch 18/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.0275 - val_loss: 0.0255\n",
            "Epoch 19/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.0222 - val_loss: 0.0191\n",
            "Epoch 20/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.0186 - val_loss: 0.0155\n",
            "Epoch 21/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.0128\n",
            "Epoch 22/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0107\n",
            "Epoch 23/34\n",
            "238/238 [==============================] - 1s 4ms/step - loss: 0.0100 - val_loss: 0.0110\n",
            "Epoch 24/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.0085 - val_loss: 0.0078\n",
            "Epoch 25/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0066\n",
            "Epoch 26/34\n",
            "238/238 [==============================] - 1s 4ms/step - loss: 0.0060 - val_loss: 0.0063\n",
            "Epoch 27/34\n",
            "238/238 [==============================] - 1s 4ms/step - loss: 0.0049 - val_loss: 0.0045\n",
            "Epoch 28/34\n",
            "238/238 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0071\n",
            "Epoch 29/34\n",
            "238/238 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0030\n",
            "Epoch 30/34\n",
            "238/238 [==============================] - 2s 7ms/step - loss: 0.0028 - val_loss: 0.0024\n",
            "Epoch 31/34\n",
            "238/238 [==============================] - 2s 7ms/step - loss: 0.0022 - val_loss: 0.0024\n",
            "Epoch 32/34\n",
            "238/238 [==============================] - 1s 5ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 33/34\n",
            "238/238 [==============================] - 1s 6ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 34/34\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 0.0013 - val_loss: 0.0025\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0023\n",
            "Test Loss: 0.0023385032545775175\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "predicted Sum: 68.00770568847656\n"
          ]
        }
      ]
    }
  ]
}